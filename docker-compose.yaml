services:
  # -----------------------
  # Kafka HA Cluster (3 brokers)
  # -----------------------
  kafka1:
    image: confluentinc/cp-kafka:7.9.1
    container_name: kafka1
    environment:
      KAFKA_NODE_ID: 1
      KAFKA_PROCESS_ROLES: broker,controller
      KAFKA_CONTROLLER_QUORUM_VOTERS: 1@kafka1:9093,2@kafka2:9093,3@kafka3:9093
      KAFKA_LISTENERS: PLAINTEXT://:9092,CONTROLLER://:9093
      KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://kafka1:9092
      KAFKA_CONTROLLER_LISTENER_NAMES: CONTROLLER
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: CONTROLLER:PLAINTEXT,PLAINTEXT:PLAINTEXT
      KAFKA_MIN_INSYNC_REPLICAS: 2
      KAFKA_DEFAULT_REPLICATION_FACTOR: 3
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 3
      CLUSTER_ID: "f1a2b3c4-5678-90ab-cdef-1234567890ab"
    volumes:
      - kafka1_data:/var/lib/kafka/data
    ports:
      - "9092:9092"
    command: >
      sh -c "
      kafka-storage.sh format --ignore-formatted -t ${CLUSTER_ID} -c /etc/kafka/kraft/server.properties || true;
      /etc/confluent/docker/run
      "
    healthcheck:
      test: ["CMD-SHELL", "kafka-broker-api-versions --bootstrap-server localhost:9092 || exit 1"]
      interval: 5s
      timeout: 10s
      retries: 10
      start_period: 45s
    restart: unless-stopped

  kafka2:
    image: confluentinc/cp-kafka:7.9.1
    container_name: kafka2
    environment:
      KAFKA_NODE_ID: 2
      KAFKA_PROCESS_ROLES: broker,controller
      KAFKA_CONTROLLER_QUORUM_VOTERS: 1@kafka1:9093,2@kafka2:9093,3@kafka3:9093
      KAFKA_LISTENERS: PLAINTEXT://:9092,CONTROLLER://:9093
      KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://kafka2:9092
      KAFKA_CONTROLLER_LISTENER_NAMES: CONTROLLER
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: CONTROLLER:PLAINTEXT,PLAINTEXT:PLAINTEXT
      KAFKA_MIN_INSYNC_REPLICAS: 2
      KAFKA_DEFAULT_REPLICATION_FACTOR: 3
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 3
      CLUSTER_ID: "f1a2b3c4-5678-90ab-cdef-1234567890ab"
    volumes:
      - kafka2_data:/var/lib/kafka/data
    command: >
      sh -c "
      kafka-storage.sh format --ignore-formatted -t ${CLUSTER_ID} -c /etc/kafka/kraft/server.properties || true;
      /etc/confluent/docker/run
      "
    healthcheck:
      test: ["CMD-SHELL", "kafka-broker-api-versions --bootstrap-server localhost:9092 || exit 1"]
      interval: 5s
      timeout: 10s
      retries: 10
      start_period: 45s
    restart: unless-stopped

  kafka3:
    image: confluentinc/cp-kafka:7.9.1
    container_name: kafka3
    environment:
      KAFKA_NODE_ID: 3
      KAFKA_PROCESS_ROLES: broker,controller
      KAFKA_CONTROLLER_QUORUM_VOTERS: 1@kafka1:9093,2@kafka2:9093,3@kafka3:9093
      KAFKA_LISTENERS: PLAINTEXT://:9092,CONTROLLER://:9093
      KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://kafka3:9092
      KAFKA_CONTROLLER_LISTENER_NAMES: CONTROLLER
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: CONTROLLER:PLAINTEXT,PLAINTEXT:PLAINTEXT
      KAFKA_MIN_INSYNC_REPLICAS: 2
      KAFKA_DEFAULT_REPLICATION_FACTOR: 3
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 3
      CLUSTER_ID: "f1a2b3c4-5678-90ab-cdef-1234567890ab"
    volumes:
      - kafka3_data:/var/lib/kafka/data
    command: >
      sh -c "
      kafka-storage.sh format --ignore-formatted -t ${CLUSTER_ID} -c /etc/kafka/kraft/server.properties || true;
      /etc/confluent/docker/run
      "
    healthcheck:
      test: ["CMD-SHELL", "kafka-broker-api-versions --bootstrap-server localhost:9092 || exit 1"]
      interval: 5s
      timeout: 10s
      retries: 10
      start_period: 45s
    restart: unless-stopped

  # -----------------------
  # MinIO HA Cluster (4 nodes)
  # -----------------------
  minio1:
    image: minio/minio
    container_name: minio1
    command: server http://minio{1...4}/data --console-address ":9001"
    environment:
      MINIO_ROOT_USER: minio
      MINIO_ROOT_PASSWORD: minio123
    volumes:
      - minio1_data:/data
    ports:
      - "9000:9000"
      - "9001:9001"
    healthcheck:
      test: ["CMD", "mc", "ready", "local"]
      interval: 10s
      timeout: 5s
      retries: 5
      start_period: 20s
    restart: unless-stopped

  minio2:
    image: minio/minio
    container_name: minio2
    command: server http://minio{1...4}/data
    environment:
      MINIO_ROOT_USER: minio
      MINIO_ROOT_PASSWORD: minio123
    volumes:
      - minio2_data:/data
    healthcheck:
      test: ["CMD", "mc", "ready", "local"]
      interval: 10s
      timeout: 5s
      retries: 5
      start_period: 20s
    restart: unless-stopped

  minio3:
    image: minio/minio
    container_name: minio3
    command: server http://minio{1...4}/data
    environment:
      MINIO_ROOT_USER: minio
      MINIO_ROOT_PASSWORD: minio123
    volumes:
      - minio3_data:/data
    healthcheck:
      test: ["CMD", "mc", "ready", "local"]
      interval: 10s
      timeout: 5s
      retries: 5
      start_period: 20s
    restart: unless-stopped

  minio4:
    image: minio/minio
    container_name: minio4
    command: server http://minio{1...4}/data
    environment:
      MINIO_ROOT_USER: minio
      MINIO_ROOT_PASSWORD: minio123
    volumes:
      - minio4_data:/data
    healthcheck:
      test: ["CMD", "mc", "ready", "local"]
      interval: 10s
      timeout: 5s
      retries: 5
      start_period: 20s
    restart: unless-stopped

  # -----------------------
  # Producer
  # -----------------------
  producer:
    build: ./producer
    depends_on:
      kafka1:
        condition: service_healthy
      kafka2:
        condition: service_healthy
      kafka3:
        condition: service_healthy
    environment:
      - KAFKA_BROKER=kafka1:9092,kafka2:9092,kafka3:9092
    restart: on-failure:5

  # -----------------------
  # Consumer
  # -----------------------
  consumer:
    build: ./consumer
    depends_on:
      kafka1:
        condition: service_healthy
      kafka2:
        condition: service_healthy
      kafka3:
        condition: service_healthy
      minio1:
        condition: service_healthy
      minio2:
        condition: service_healthy
      minio3:
        condition: service_healthy
      minio4:
        condition: service_healthy
    environment:
      - KAFKA_BROKER=kafka1:9092,kafka2:9092,kafka3:9092
      - MINIO_ENDPOINT=minio1:9000
      - MINIO_ACCESS_KEY=minio
      - MINIO_SECRET_KEY=minio123
      - MINIO_BUCKET=telco-churn
    env_file:
      - .env
    restart: on-failure:5

  # -----------------------
  # Spark Job
  # -----------------------
  spark:
    build:
      context: ./spark
      dockerfile: Dockerfile
    container_name: spark
    user: root
    depends_on:
      minio1:
        condition: service_healthy
      minio2:
        condition: service_healthy
      minio3:
        condition: service_healthy
      minio4:
        condition: service_healthy
    environment:
      - AWS_ACCESS_KEY_ID=minio
      - AWS_SECRET_ACCESS_KEY=minio123
      - SPARK_HOME=/opt/spark
      - IVY_HOME=/opt/ivy2
    volumes:
      - ./spark/app:/opt/spark/app
      - spark-ivy-cache:/opt/ivy2
    command: >
      /opt/spark/bin/spark-submit
      --packages io.delta:delta-spark_2.13:3.2.0,org.apache.hadoop:hadoop-aws:3.3.4
      --conf spark.sql.extensions=io.delta.sql.DeltaSparkSessionExtension
      --conf spark.sql.catalog.spark_catalog=org.apache.spark.sql.delta.catalog.DeltaCatalog
      --conf spark.hadoop.fs.s3a.endpoint=http://minio1:9000
      --conf spark.hadoop.fs.s3a.access.key=minio
      --conf spark.hadoop.fs.s3a.secret.key=minio123
      --conf spark.hadoop.fs.s3a.path.style.access=true
      --conf spark.hadoop.fs.s3a.impl=org.apache.hadoop.fs.s3a.S3AFileSystem
      /opt/spark/app/delta_job.py

volumes:
  kafka1_data:
  kafka2_data:
  kafka3_data:
  minio1_data:
  minio2_data:
  minio3_data:
  minio4_data:
  spark-ivy-cache:
